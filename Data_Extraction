# data_acquisition.py

import time
import io
import requests
import numpy as np
import pandas as pd
from bs4 import BeautifulSoup

AIRFOILTOOLS_BASE = "https://airfoiltools.com"

HEADERS = {
    "User-Agent": "Mozilla/5.0 (compatible; airfoil-ml-bot/0.1; +https://github.com/your-repo)"
}

session = requests.Session()
session.headers.update(HEADERS)


def safe_get(url, params=None, sleep=0.5):
    """Wrapper around requests.get with basic error handling and optional delay."""
    time.sleep(sleep)  # be polite
    resp = session.get(url, params=params, timeout=15)
    resp.raise_for_status()
    return resp


def build_airfoil_details_url(airfoil_id: str) -> str:
    """
    Airfoil details page, e.g.
    https://airfoiltools.com/airfoil/details?airfoil=naca2412-il
    """
    return f"{AIRFOILTOOLS_BASE}/airfoil/details?airfoil={airfoil_id}"


def build_airfoil_dat_url(airfoil_id: str) -> str:
    """
    URL to the coordinate .dat file.

    On AirfoilTools, the details page usually has a link to a .dat file.
    For many airfoils, it's something like:
      https://airfoiltools.com/airfoil/coords?airfoil=naca2412-il

    You MUST confirm this by inspecting the actual page and update if needed.
    """
    return f"{AIRFOILTOOLS_BASE}/airfoil/coords?airfoil={airfoil_id}"  # <-- confirm pattern


def fetch_airfoil_coords(airfoil_id: str) -> pd.DataFrame:
    """
    Download airfoil coordinates from AirfoilTools and return as DataFrame with columns ['x', 'y'].
    """
    url = build_airfoil_dat_url(airfoil_id)
    resp = safe_get(url)
    text = resp.text

    try:
        data = np.loadtxt(io.StringIO(text), comments="#", skiprows=1)
    except Exception:
        data = np.loadtxt(io.StringIO(text), comments="#", skiprows=0)

    if data.ndim == 1:
        data = data.reshape(-1, 2)

    df = pd.DataFrame(data, columns=["x", "y"])
    return df


def discover_polar_ids_for_airfoil(airfoil_id: str):
    """
    Given an airfoil (e.g., 'naca2412-il'), parse its details page
    and extract the available polar IDs (e.g., 'xf-naca2412-il-50000').

    TODO: Inspect the HTML of the airfoil details page in a browser and
    adapt the parsing logic to the actual structure.
    """
    url = build_airfoil_details_url(airfoil_id)
    resp = safe_get(url)
    soup = BeautifulSoup(resp.text, "html.parser")

    polar_ids = []

    # Example placeholder logic:
    for a in soup.find_all("a", href=True):
        href = a["href"]
        if "polar/details?polar=" in href:
            pol = href.split("polar=")[-1]
            polar_ids.append(pol)

    return list(sorted(set(polar_ids)))


def build_polar_details_url(polar_id: str) -> str:
    """
    Polar details page, e.g.
    https://airfoiltools.com/polar/details?polar=xf-naca2412-il-50000
    """
    return f"{AIRFOILTOOLS_BASE}/polar/details?polar={polar_id}"


def fetch_polar_table(polar_id: str) -> pd.DataFrame:
    """
    Fetch the Cl, Cd, Cm vs alpha table from a polar details page.

    TODO: Inspect the HTML structure of the polar page and adjust table selection logic.
    """
    url = build_polar_details_url(polar_id)
    resp = safe_get(url)
    soup = BeautifulSoup(resp.text, "html.parser")

    table = soup.find("table")
    if table is None:
        raise RuntimeError(f"No table found for polar {polar_id}")

    header_row = table.find("tr")
    headers = [th.get_text(strip=True).lower() for th in header_row.find_all("th")]

    rows = []
    for tr in table.find_all("tr")[1:]:
        tds = tr.find_all("td")
        if not tds:
            continue
        row = [td.get_text(strip=True) for td in tds]
        if len(row) != len(headers):
            continue
        rows.append(row)

    df = pd.DataFrame(rows, columns=headers)

    # Try converting columns to numeric when possible
    for col in df.columns:
        df[col] = pd.to_numeric(df[col], errors="ignore")

    return df
